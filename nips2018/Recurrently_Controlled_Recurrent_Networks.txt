#Abstract
    递归神经网络(RNNs)，如长短期记忆和门控递归单元，是一个广泛的序列建模问题的关键构件。
    提出了一种表达性强的序列编码递归控制递归网络(RCRN)。更具体地说，我们的方法背后的关键思想是利用递归网络学习递归门函数。
    我们的体系结构分为两个组件——一个控制器单元和一个侦听器单元，其中循环控制器积极地影响侦听器单元的组合性。
    我们对NLP领域的大量任务进行了广泛的实验，如情绪分析(SST, IMDb, Amazon reviews等)、问题分类(TREC)、隐含分类(SNLI, SciTail)、答案选择(WikiQA, TrecQA)和阅读理解(NarrativeQA)。
    在所有26个数据集中，我们的结果表明RCRN不仅始终优于BiLSTMs，而且优于叠加的BiLSTMs，这表明我们的控制器架构可能是广泛采用的叠加架构的合适替代品。


#Introduction
    ##现有RNNs GRU LSTM
    ##有两种常见的方法可以提高神经网络的表示能力：
        首先，可以增加隐藏维数。
        其次，递归层可以层次化的层叠在一起[El Hihi and Bengio, 1996]，每一层的输入都是上一层的输出，这样就可以捕获层次化的特征。
    ##存在问题：
        前者可能存在过度拟合和/或在性能上碰壁的风险。
        另一方面，后者可能会面临深入的固有困难，如梯度消失或特征跨深度RNN层传播困难[Zhang et al.， 2016b]。

    提出了一种新的递归结构——递归控制递归网络(RCRN)。
    rcrn的特点是它使用了两个关键组件——一个循环控制器单元和一个侦听器单元。控制器单元控制侦听器RNN的信息流和组合性。
    RCRN背后的主要动机是提供具有表现力和强大的序列编码。
    然而，与层叠架构不同的是，所有RNN层在相同的层次结构上共同操作，有效地避免了进一步深入的需要。
    因此，通过允许一个RNN控制另一个RNN, rcrn提供了一种新的替代方法来联合使用多个RNN层。
    因此，我们在这项工作中的主要目标是证明我们提出的控制器-侦听器体系结构是广泛采用的层叠递归体系结构的可行替代品。

    为了证明我们提出的RCRN模型的有效性，我们对大量不同的NLP任务进行了广泛的实验，其中序列编码器如LSTMs/GRUs是非常重要的。
    这些任务包括情绪分析(SST, IMDb, Amazon Reviews)，问题分类(TREC)，隐含分类(SNLI, SciTail)，答案选择(WikiQA, TrecQA)和阅读理解(NarrativeQA)。
    实验结果表明，RCRN在26个数据集上的性能均优于BiLSTMs和多层/堆叠BiLSTMs，表明RCRN是广泛采用的堆叠递归架构的可行替代品。
    此外，RCRN在几个数据集上实现了接近最先进的性能。


#Experiment
    Dataset/Model BiLSTM 2L-BiLSTM SLSTM BiLSTMy 3L-BiLSTMy RCRN
    Camera        87.1   88.1      90.0  87.3    89.7       90.5
    Video         84.7   85.2      86.8  87.5    87.8       88.5
    Health        85.5   85.9      86.5  85.5    89.0       90.5
    Music         78.7   80.5      82.0  83.5    85.7       86.0
    Kitchen       82.2   83.8      84.5  81.7    84.5       86.0
    DVD           83.7   84.8      85.5  84.0    86.0       86.8
    Toys          85.7   85.8      85.3  87.5    90.5       90.8
    Baby          84.5   85.5      86.3  85.0    88.5       89.0
    Books         82.1   82.8      83.4  86.0    87.2       88.0
    IMDB          86.0   86.6      87.2  86.5    88.0       89.8
    MR            75.7   76.0      76.2  77.7    77.7       79.0
    Apparel       86.1   86.4      85.8  88.0    89.2       90.5
    Magazines     92.6   92.9      93.8  93.7    92.5       94.8
    Electronics   82.5   82.3      83.3  83.5    87.0       89.0
    Sports        84.0   84.8      85.8  85.5    86.5       88.0
    Software      86.7   87.0      87.8  88.5    90.3       90.8
    Macro Avg     84.3   84.9      85.6  85.7    87.5       88.6
    Table 1: Results on the Amazon Reviews dataset. y are models implemented by us

    整体结果：
    在所有26个数据集中，RCRN不仅优于标准BiLSTMs，而且优于参数化近似相等的3L-BiLSTMs。3L-BiLSTMs总体上优于BiLSTMs，但在少数数据集上有所损失。
    RCRN的表现优于一系列具有竞争力的基线，如DiSAN、Bi-SRUs、BCN和LSTM-CNN等。我们在SST、TREC问题分类和16个Amazon review数据集上实现了(接近)最先进的性能。

#Conclusion
    我们提出了递归控制递归网络(RCRN)，一个新的递归架构和编码器，为无数的NLP任务。RCRN以一种新颖的控制器-监听器架构运行，该架构使用RNN来学习另一个RNN的门控函数。
    我们将RCRN应用于大量的NLP任务，并在所有任务和26个基准数据集上实现了有前途的/极具竞争力的结果。总体结果表明，我们的控制器-侦听器架构比叠加RNN层更有效。
    此外，与近似相等参数化的堆叠rnn相比，RCRN的效率仍然相同(或略高)。有几个潜在的有趣的方向进一步研究RCRNs。
    首先，研究rcrn控制其他rcrn，其次，研究rcrn在其他领域的复发模型也普遍用于序列建模。
    我们模型的源代码可以在https://github.com/vanzytay /NIPS2018_RCRN中找到。